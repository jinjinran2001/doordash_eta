{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# DoorDash ETA Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:04:30.008250Z",
     "iopub.status.busy": "2025-04-21T17:04:30.007353Z",
     "iopub.status.idle": "2025-04-21T17:04:30.093932Z",
     "shell.execute_reply": "2025-04-21T17:04:30.093195Z",
     "shell.execute_reply.started": "2025-04-21T17:04:30.008216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:36.534426Z",
     "iopub.status.busy": "2025-04-21T16:53:36.533823Z",
     "iopub.status.idle": "2025-04-21T16:53:37.143604Z",
     "shell.execute_reply": "2025-04-21T16:53:37.142764Z",
     "shell.execute_reply.started": "2025-04-21T16:53:36.534398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/doordash-eta-prediction/historical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.145021Z",
     "iopub.status.busy": "2025-04-21T16:53:37.144769Z",
     "iopub.status.idle": "2025-04-21T16:53:37.168501Z",
     "shell.execute_reply": "2025-04-21T16:53:37.167684Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.144997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>actual_delivery_time</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_primary_category</th>\n",
       "      <th>order_protocol</th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>total_onshift_dashers</th>\n",
       "      <th>total_busy_dashers</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>estimated_order_place_duration</th>\n",
       "      <th>estimated_store_to_consumer_driving_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-02-06 22:24:17</td>\n",
       "      <td>2015-02-06 23:27:16</td>\n",
       "      <td>1845</td>\n",
       "      <td>american</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3441</td>\n",
       "      <td>4</td>\n",
       "      <td>557</td>\n",
       "      <td>1239</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>446</td>\n",
       "      <td>861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-10 21:49:25</td>\n",
       "      <td>2015-02-10 22:56:29</td>\n",
       "      <td>5477</td>\n",
       "      <td>mexican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>446</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-01-22 20:39:28</td>\n",
       "      <td>2015-01-22 21:09:09</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-03 21:21:45</td>\n",
       "      <td>2015-02-03 22:13:00</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6900</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>446</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-15 02:40:36</td>\n",
       "      <td>2015-02-15 03:20:26</td>\n",
       "      <td>5477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3900</td>\n",
       "      <td>3</td>\n",
       "      <td>1100</td>\n",
       "      <td>1600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>446</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_id           created_at actual_delivery_time  store_id  \\\n",
       "0        1.0  2015-02-06 22:24:17  2015-02-06 23:27:16      1845   \n",
       "1        2.0  2015-02-10 21:49:25  2015-02-10 22:56:29      5477   \n",
       "2        3.0  2015-01-22 20:39:28  2015-01-22 21:09:09      5477   \n",
       "3        3.0  2015-02-03 21:21:45  2015-02-03 22:13:00      5477   \n",
       "4        3.0  2015-02-15 02:40:36  2015-02-15 03:20:26      5477   \n",
       "\n",
       "  store_primary_category  order_protocol  total_items  subtotal  \\\n",
       "0               american             1.0            4      3441   \n",
       "1                mexican             2.0            1      1900   \n",
       "2                    NaN             1.0            1      1900   \n",
       "3                    NaN             1.0            6      6900   \n",
       "4                    NaN             1.0            3      3900   \n",
       "\n",
       "   num_distinct_items  min_item_price  max_item_price  total_onshift_dashers  \\\n",
       "0                   4             557            1239                   33.0   \n",
       "1                   1            1400            1400                    1.0   \n",
       "2                   1            1900            1900                    1.0   \n",
       "3                   5             600            1800                    1.0   \n",
       "4                   3            1100            1600                    6.0   \n",
       "\n",
       "   total_busy_dashers  total_outstanding_orders  \\\n",
       "0                14.0                      21.0   \n",
       "1                 2.0                       2.0   \n",
       "2                 0.0                       0.0   \n",
       "3                 1.0                       2.0   \n",
       "4                 6.0                       9.0   \n",
       "\n",
       "   estimated_order_place_duration  \\\n",
       "0                             446   \n",
       "1                             446   \n",
       "2                             446   \n",
       "3                             446   \n",
       "4                             446   \n",
       "\n",
       "   estimated_store_to_consumer_driving_duration  \n",
       "0                                         861.0  \n",
       "1                                         690.0  \n",
       "2                                         690.0  \n",
       "3                                         289.0  \n",
       "4                                         650.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Convert and Extract Datetime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.338086Z",
     "iopub.status.busy": "2025-04-21T16:53:37.337375Z",
     "iopub.status.idle": "2025-04-21T16:53:37.814371Z",
     "shell.execute_reply": "2025-04-21T16:53:37.813400Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.338039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data['actual_delivery_time'] = pd.to_datetime(data['actual_delivery_time'])\n",
    "data['delivery_duration_minutes'] = (\n",
    "    (data['actual_delivery_time'] - data['created_at']).dt.total_seconds() / 60\n",
    ")\n",
    "\n",
    "# Time-Based Features\n",
    "data['hour'] = data['created_at'].dt.hour\n",
    "data['day_of_week_num'] = data['created_at'].dt.dayofweek\n",
    "data['is_weekend'] = data['day_of_week_num'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Holiday Indicator\n",
    "us_holidays = holidays.US()\n",
    "data['is_holiday'] = data['created_at'].dt.date.astype(str).isin(us_holidays).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.817233Z",
     "iopub.status.busy": "2025-04-21T16:53:37.816893Z",
     "iopub.status.idle": "2025-04-21T16:53:37.827205Z",
     "shell.execute_reply": "2025-04-21T16:53:37.826374Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.817205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['total_busy_dashers'] = abs(data['total_busy_dashers'])  # Handle negative values\n",
    "data['total_onshift_dashers'] = abs(data['total_onshift_dashers'])\n",
    "data['dashers_per_order'] = data['total_onshift_dashers'] / (data['total_outstanding_orders'] + 1e-5)\n",
    "data['%_dashers_avail'] = data['total_busy_dashers'] / (\n",
    "    data['total_busy_dashers'] + data['total_onshift_dashers'] + 1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.828850Z",
     "iopub.status.busy": "2025-04-21T16:53:37.828386Z",
     "iopub.status.idle": "2025-04-21T16:53:37.838126Z",
     "shell.execute_reply": "2025-04-21T16:53:37.837137Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.828811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['price_range'] = data['max_item_price'] - data['min_item_price']\n",
    "data['avg_item_price'] = data['subtotal'] / (data['total_items'] + 1e-5)\n",
    "data['price_volatility'] = data['price_range'] / (data['avg_item_price'] + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.839361Z",
     "iopub.status.busy": "2025-04-21T16:53:37.839116Z",
     "iopub.status.idle": "2025-04-21T16:53:37.846598Z",
     "shell.execute_reply": "2025-04-21T16:53:37.845815Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.839338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Interaction Features\n",
    "data['order_intensity'] = data['total_outstanding_orders'] / (data['total_busy_dashers'] + 1e-5)\n",
    "data['delivery_difficulty'] = data['order_intensity'] * data['estimated_store_to_consumer_driving_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.848128Z",
     "iopub.status.busy": "2025-04-21T16:53:37.847894Z",
     "iopub.status.idle": "2025-04-21T16:53:37.882906Z",
     "shell.execute_reply": "2025-04-21T16:53:37.881734Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.848104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['historical_avg_delivery_time'] = data.groupby(\n",
    "    ['store_id', 'hour'])['delivery_duration_minutes'].transform('mean')\n",
    "\n",
    "data['delivery_speed'] = data['historical_avg_delivery_time'] / (\n",
    "    data['estimated_store_to_consumer_driving_duration'] / 60 + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.884322Z",
     "iopub.status.busy": "2025-04-21T16:53:37.884005Z",
     "iopub.status.idle": "2025-04-21T16:53:37.894729Z",
     "shell.execute_reply": "2025-04-21T16:53:37.893652Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.884288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['log_subtotal'] = np.log1p(data['subtotal'])\n",
    "data['log_outstanding_orders'] = np.log1p(data['total_outstanding_orders'].clip(lower=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:37.896508Z",
     "iopub.status.busy": "2025-04-21T16:53:37.896071Z",
     "iopub.status.idle": "2025-04-21T16:53:37.938474Z",
     "shell.execute_reply": "2025-04-21T16:53:37.937573Z",
     "shell.execute_reply.started": "2025-04-21T16:53:37.896455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=['created_at', 'actual_delivery_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Outlier Removal Using IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:42.328399Z",
     "iopub.status.busy": "2025-04-21T16:53:42.327704Z",
     "iopub.status.idle": "2025-04-21T16:53:42.552434Z",
     "shell.execute_reply": "2025-04-21T16:53:42.551750Z",
     "shell.execute_reply.started": "2025-04-21T16:53:42.328336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, variables, threshold=1.5):\n",
    "   \n",
    "    for variable in variables:\n",
    "        if variable in df.columns:\n",
    "            Q1 = df[variable].quantile(0.25)\n",
    "            Q3 = df[variable].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - (threshold * IQR)\n",
    "            upper_bound = Q3 + (threshold * IQR)\n",
    "            df = df[(df[variable] >= lower_bound) & (df[variable] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Define numerical columns with potential outliers\n",
    "outlier_columns = [\n",
    "    'subtotal', 'delivery_duration_minutes', 'max_item_price', 'price_range',\n",
    "    'avg_item_price', 'price_volatility', 'delivery_speed'\n",
    "]\n",
    "\n",
    "# Remove outliers\n",
    "data = remove_outliers_iqr(data, outlier_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Handling Missing Values in the Dataset\n",
    "### Using KNN Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T16:53:42.553863Z",
     "iopub.status.busy": "2025-04-21T16:53:42.553486Z",
     "iopub.status.idle": "2025-04-21T17:00:34.549587Z",
     "shell.execute_reply": "2025-04-21T17:00:34.548587Z",
     "shell.execute_reply.started": "2025-04-21T16:53:42.553827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column after imputation:\n",
      "market_id                                       0\n",
      "store_id                                        0\n",
      "store_primary_category                          0\n",
      "order_protocol                                  0\n",
      "total_items                                     0\n",
      "subtotal                                        0\n",
      "num_distinct_items                              0\n",
      "min_item_price                                  0\n",
      "max_item_price                                  0\n",
      "total_onshift_dashers                           0\n",
      "total_busy_dashers                              0\n",
      "total_outstanding_orders                        0\n",
      "estimated_order_place_duration                  0\n",
      "estimated_store_to_consumer_driving_duration    0\n",
      "delivery_duration_minutes                       0\n",
      "hour                                            0\n",
      "day_of_week_num                                 0\n",
      "is_weekend                                      0\n",
      "is_holiday                                      0\n",
      "dashers_per_order                               0\n",
      "%_dashers_avail                                 0\n",
      "price_range                                     0\n",
      "avg_item_price                                  0\n",
      "price_volatility                                0\n",
      "order_intensity                                 0\n",
      "delivery_difficulty                             0\n",
      "historical_avg_delivery_time                    0\n",
      "delivery_speed                                  0\n",
      "log_subtotal                                    0\n",
      "log_outstanding_orders                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, n_neighbors=5):\n",
    "    \n",
    "    # Handle numerical columns using KNN Imputer\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    # Handle categorical columns using mode imputation\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply missing value handling\n",
    "data = handle_missing_values(data)\n",
    "print(\"Missing values per column after imputation:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:00:34.559269Z",
     "iopub.status.busy": "2025-04-21T17:00:34.558991Z",
     "iopub.status.idle": "2025-04-21T17:00:34.597367Z",
     "shell.execute_reply": "2025-04-21T17:00:34.596565Z",
     "shell.execute_reply.started": "2025-04-21T17:00:34.559243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 46, 35, 38, 58, 68, 15, 55, 20, 60, 13, 10, 45, 39, 18, 28, 33,\n",
       "       50, 40, 70,  6,  7, 27, 59, 72, 22, 65, 16, 23, 62, 71, 57, 53, 66,\n",
       "       42, 34, 11, 49, 52,  2, 24, 61, 54, 69, 44, 25, 47,  0, 12, 31, 29,\n",
       "       17, 21, 32, 30, 14, 48, 51, 64, 63, 67, 56,  9, 26, 19,  1,  5, 37,\n",
       "       43, 41,  8, 36,  3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimized_label_encoding(df, cat_cols):\n",
    "    le_dict = {} \n",
    "    \n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        le_dict[col] = le \n",
    "    \n",
    "    return df, le_dict\n",
    "    \n",
    "categorical_columns = ['store_primary_category']\n",
    "data, encoders = optimized_label_encoding(data, categorical_columns)\n",
    "\n",
    "data['store_primary_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:00:34.598505Z",
     "iopub.status.busy": "2025-04-21T17:00:34.598282Z",
     "iopub.status.idle": "2025-04-21T17:00:34.617825Z",
     "shell.execute_reply": "2025-04-21T17:00:34.616988Z",
     "shell.execute_reply.started": "2025-04-21T17:00:34.598483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Target and feature variables\n",
    "X = data.drop(columns=['delivery_duration_minutes'])\n",
    "y = data['delivery_duration_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:00:34.619336Z",
     "iopub.status.busy": "2025-04-21T17:00:34.618952Z",
     "iopub.status.idle": "2025-04-21T17:00:34.746043Z",
     "shell.execute_reply": "2025-04-21T17:00:34.745305Z",
     "shell.execute_reply.started": "2025-04-21T17:00:34.619294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Random Forest Model for Predicting Delivery Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:06:33.882725Z",
     "iopub.status.busy": "2025-04-21T17:06:33.882301Z",
     "iopub.status.idle": "2025-04-21T17:15:02.997594Z",
     "shell.execute_reply": "2025-04-21T17:15:02.996492Z",
     "shell.execute_reply.started": "2025-04-21T17:06:33.882664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 8.02\n",
      "Root Mean Squared Error (RMSE): 10.40\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:25:53.809851Z",
     "iopub.status.busy": "2025-04-21T17:25:53.809118Z",
     "iopub.status.idle": "2025-04-21T17:25:54.421387Z",
     "shell.execute_reply": "2025-04-21T17:25:54.420437Z",
     "shell.execute_reply.started": "2025-04-21T17:25:53.809818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:27:05.586351Z",
     "iopub.status.busy": "2025-04-21T17:27:05.585527Z",
     "iopub.status.idle": "2025-04-21T17:27:06.454818Z",
     "shell.execute_reply": "2025-04-21T17:27:06.453890Z",
     "shell.execute_reply.started": "2025-04-21T17:27:05.586318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sklearn]   MAE: 8.0174  RMSE: 10.3989  Time: 0.0031 sec\n",
      "[Numba]     MAE: 8.0174  RMSE: 10.3989  Time: 0.8569 sec\n",
      "Results match: True True\n"
     ]
    }
   ],
   "source": [
    "# Sklearn\n",
    "start = time.time()\n",
    "mae_sklearn = mean_absolute_error(y_test, y_pred)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "t_sklearn = time.time() - start\n",
    "print(f\"[Sklearn]   MAE: {mae_sklearn:.4f}  RMSE: {rmse_sklearn:.4f}  Time: {t_sklearn:.4f} sec\")\n",
    "\n",
    "# Numba\n",
    "@njit(parallel=True)\n",
    "def mae_numba(y_true, y_pred):\n",
    "    error = 0.0\n",
    "    for i in prange(len(y_true)):\n",
    "        error += abs(y_true[i] - y_pred[i])\n",
    "    return error / len(y_true)\n",
    "\n",
    "@njit(parallel=True)\n",
    "def rmse_numba(y_true, y_pred):\n",
    "    total = 0.0\n",
    "    for i in prange(len(y_true)):\n",
    "        diff = y_true[i] - y_pred[i]\n",
    "        total += diff * diff\n",
    "    return np.sqrt(total / len(y_true))\n",
    "\n",
    "start = time.time()\n",
    "mae_n = mae_numba(y_test.values, y_pred)\n",
    "rmse_n = rmse_numba(y_test.values, y_pred)\n",
    "t_numba = time.time() - start\n",
    "print(f\"[Numba]     MAE: {mae_n:.4f}  RMSE: {rmse_n:.4f}  Time: {t_numba:.4f} sec\")\n",
    "\n",
    "print(\"Results match:\", np.allclose(mae_sklearn, mae_n), np.allclose(rmse_sklearn, rmse_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T17:44:06.968056Z",
     "iopub.status.busy": "2025-04-21T17:44:06.967289Z",
     "iopub.status.idle": "2025-04-21T17:53:31.223879Z",
     "shell.execute_reply": "2025-04-21T17:53:31.222860Z",
     "shell.execute_reply.started": "2025-04-21T17:44:06.968025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Parallel (n_jobs=3) ====\n",
      "Seed: 0  MAE: 8.0337  RMSE: 10.4160\n",
      "Seed: 1  MAE: 8.0336  RMSE: 10.4184\n",
      "Seed: 2  MAE: 8.0458  RMSE: 10.4334\n",
      "Total time: 288.54 seconds\n",
      "\n",
      "==== Sequential (for-loop) ====\n",
      "Seed: 0  MAE: 8.0337  RMSE: 10.4160\n",
      "Seed: 1  MAE: 8.0336  RMSE: 10.4184\n",
      "Seed: 2  MAE: 8.0458  RMSE: 10.4334\n",
      "Total time: 275.71 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Assumes the following data already exists:\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to train and evaluate a single Random Forest model\n",
    "def train_rf(X_train, y_train, X_test, y_test, seed):\n",
    "    model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return {\"seed\": seed, \"mae\": mae, \"rmse\": rmse}\n",
    "\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "# ✅ Parallel training using joblib\n",
    "start_parallel = time.time()\n",
    "results_parallel = Parallel(n_jobs=3)(\n",
    "    delayed(train_rf)(X_train, y_train, X_test, y_test, seed) for seed in seeds\n",
    ")\n",
    "time_parallel = time.time() - start_parallel\n",
    "\n",
    "# ✅ Sequential training using a regular for-loop\n",
    "start_sequential = time.time()\n",
    "results_sequential = []\n",
    "for seed in seeds:\n",
    "    results_sequential.append(train_rf(X_train, y_train, X_test, y_test, seed))\n",
    "time_sequential = time.time() - start_sequential\n",
    "\n",
    "# ✅ Output results for comparison\n",
    "print(\"==== Parallel (n_jobs=3) ====\")\n",
    "for r in results_parallel:\n",
    "    print(f\"Seed: {r['seed']}  MAE: {r['mae']:.4f}  RMSE: {r['rmse']:.4f}\")\n",
    "print(f\"Total time: {time_parallel:.2f} seconds\\n\")\n",
    "\n",
    "print(\"==== Sequential (for-loop) ====\")\n",
    "for r in results_sequential:\n",
    "    print(f\"Seed: {r['seed']}  MAE: {r['mae']:.4f}  RMSE: {r['rmse']:.4f}\")\n",
    "print(f\"Total time: {time_sequential:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-04-21T18:03:52.362430Z",
     "iopub.status.busy": "2025-04-21T18:03:52.361486Z",
     "iopub.status.idle": "2025-04-21T18:09:34.688033Z",
     "shell.execute_reply": "2025-04-21T18:09:34.687045Z",
     "shell.execute_reply.started": "2025-04-21T18:03:52.362394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest (n_jobs=None) ===\n",
      "Training Time: 250.53 seconds\n",
      "MAE: 8.03\n",
      "RMSE: 10.42\n",
      "\n",
      "=== Random Forest (n_jobs=-1) ===\n",
      "Training Time: 91.79 seconds\n",
      "MAE: 8.03\n",
      "RMSE: 10.42\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ------- Version 1: n_jobs=None -------\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model_single = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=None  # default: single thread\n",
    ")\n",
    "\n",
    "rf_model_single.fit(X_train, y_train)\n",
    "y_pred_single = rf_model_single.predict(X_test)\n",
    "\n",
    "time_single = time.time() - start_time\n",
    "mae_single = mean_absolute_error(y_test, y_pred_single)\n",
    "rmse_single = np.sqrt(mean_squared_error(y_test, y_pred_single))\n",
    "\n",
    "print(\"=== Random Forest (n_jobs=None) ===\")\n",
    "print(f\"Training Time: {time_single:.2f} seconds\")\n",
    "print(f\"MAE: {mae_single:.2f}\")\n",
    "print(f\"RMSE: {rmse_single:.2f}\\n\")\n",
    "\n",
    "\n",
    "# ------- Version 2: n_jobs=-1 -------\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model_parallel = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # all available cores\n",
    ")\n",
    "\n",
    "rf_model_parallel.fit(X_train, y_train)\n",
    "y_pred_parallel = rf_model_parallel.predict(X_test)\n",
    "\n",
    "time_parallel = time.time() - start_time\n",
    "mae_parallel = mean_absolute_error(y_test, y_pred_parallel)\n",
    "rmse_parallel = np.sqrt(mean_squared_error(y_test, y_pred_parallel))\n",
    "\n",
    "print(\"=== Random Forest (n_jobs=-1) ===\")\n",
    "print(f\"Training Time: {time_parallel:.2f} seconds\")\n",
    "print(f\"MAE: {mae_parallel:.2f}\")\n",
    "print(f\"RMSE: {rmse_parallel:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5234554,
     "sourceId": 8722910,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
